#!/usr/bin/env python3
"""
Script de Teste - Pipeline com Amostra Pequena
Objetivo: Testar o pipeline antes de processar todos os dados
"""

import asyncio
import pandas as pd
import json
from main_pipeline import CAPESDOIEnricher

async def test_pipeline_sample():
    """
    Testa o pipeline com uma amostra pequena
    """
    print("üß™ TESTE DO PIPELINE COM AMOSTRA")
    print("="*50)
    
    # Carregar apenas uma pequena amostra
    print("üì• Carregando amostra...")
    df1 = pd.read_csv('data/raw/capes_parte1.csv', 
                     encoding='ISO-8859-1', 
                     sep=';', 
                     nrows=1000,  # Apenas 1000 registros para teste
                     low_memory=False)
    
    print(f"‚úÖ {len(df1):,} registros carregados para teste")
    
    # Filtrar apenas registros com t√≠tulos v√°lidos
    valid_df = df1[df1['NM_PRODUCAO'].notna() & (df1['NM_PRODUCAO'] != '')].head(50)
    print(f"üéØ Testando com {len(valid_df)} registros v√°lidos")
    
    # Mostrar alguns t√≠tulos de exemplo
    print("\nüìù T√≠tulos de exemplo que ser√£o processados:")
    for i, title in enumerate(valid_df['NM_PRODUCAO'].head(5), 1):
        print(f"   {i}. {title[:80]}...")
    
    # Inicializar enricher com configura√ß√µes de teste
    enricher = CAPESDOIEnricher(
        cache_db='data/processed/test_cache.db',
        max_concurrent=5  # Menor concorr√™ncia para teste
    )
    enricher.rate_limit = 10  # Mais conservador para teste
    enricher.batch_size = 10  # Lotes menores
    
    # Executar enriquecimento
    print("\nüîÑ Iniciando enriquecimento de teste...")
    start_time = asyncio.get_event_loop().time()
    
    df_enriched = await enricher.enrich_dataset(valid_df)
    
    end_time = asyncio.get_event_loop().time()
    duration = end_time - start_time
    
    # Analisar resultados
    print("\nüìä RESULTADOS DO TESTE:")
    print("="*30)
    
    total_processed = len(df_enriched)
    dois_found = df_enriched['DOI'].notna().sum()
    success_rate = (dois_found / total_processed) * 100 if total_processed > 0 else 0
    
    print(f"‚è±Ô∏è  Tempo de execu√ß√£o: {duration:.1f} segundos")
    print(f"üìä Registros processados: {total_processed}")
    print(f"üìä DOIs encontrados: {dois_found}")
    print(f"üìä Taxa de sucesso: {success_rate:.1f}%")
    print(f"üöÄ Velocidade: {total_processed/duration:.1f} registros/segundo")
    
    if dois_found > 0:
        avg_similarity = df_enriched[df_enriched['DOI'].notna()]['SIMILARITY_SCORE'].mean()
        print(f"üìä Similaridade m√©dia: {avg_similarity:.1f}%")
    
    # Mostrar alguns exemplos de sucesso
    successful_matches = df_enriched[df_enriched['DOI'].notna()].head(3)
    if len(successful_matches) > 0:
        print(f"\n‚úÖ Exemplos de matches encontrados:")
        for idx, row in successful_matches.iterrows():
            print(f"\n   Original: {row['NM_PRODUCAO'][:60]}...")
            print(f"   Crossref: {row['CROSSREF_TITLE'][:60]}...")
            print(f"   DOI: {row['DOI']}")
            print(f"   Similaridade: {row['SIMILARITY_SCORE']:.1f}%")
    
    # Salvar resultado do teste
    test_output = 'data/processed/test_results.csv'
    df_enriched.to_csv(test_output, index=False, encoding='utf-8')
    print(f"\nüíæ Resultados do teste salvos em: {test_output}")
    
    # Estimativa para dataset completo
    if duration > 0:
        total_records = 1162324  # Total conhecido
        estimated_hours = (total_records * duration) / (total_processed * 3600)
        print(f"\nüîÆ ESTIMATIVA PARA DATASET COMPLETO:")
        print(f"   üìä Total de registros: {total_records:,}")
        print(f"   ‚è±Ô∏è  Tempo estimado: {estimated_hours:.1f} horas")
        print(f"   üìä DOIs estimados: {int(total_records * success_rate / 100):,}")
    
    return df_enriched

def analyze_test_results():
    """
    Analisa os resultados do teste salvo
    """
    try:
        df = pd.read_csv('data/processed/test_results.csv')
        
        print("\nüìà AN√ÅLISE DETALHADA DOS RESULTADOS:")
        print("="*40)
        
        # Distribui√ß√£o de scores de similaridade
        similarity_scores = df[df['DOI'].notna()]['SIMILARITY_SCORE']
        if len(similarity_scores) > 0:
            print(f"üìä Distribui√ß√£o de scores de similaridade:")
            print(f"   M√≠nimo: {similarity_scores.min():.1f}%")
            print(f"   M√°ximo: {similarity_scores.max():.1f}%")
            print(f"   M√©dia: {similarity_scores.mean():.1f}%")
            print(f"   Mediana: {similarity_scores.median():.1f}%")
        
        # Cache usage
        cache_usage = df['FROM_CACHE'].sum() if 'FROM_CACHE' in df.columns else 0
        print(f"üìä Uso do cache: {cache_usage}/{len(df)} ({cache_usage/len(df)*100:.1f}%)")
        
        # T√≠tulos n√£o encontrados
        not_found = df[df['DOI'].isna()]
        if len(not_found) > 0:
            print(f"\n‚ùå Exemplos de t√≠tulos n√£o encontrados:")
            for title in not_found['NM_PRODUCAO'].head(3):
                print(f"   ‚Ä¢ {title[:70]}...")
                
    except FileNotFoundError:
        print("‚ùå Arquivo de teste n√£o encontrado. Execute o teste primeiro.")

async def main():
    """
    Executa teste e an√°lise
    """
    # Executar teste
    await test_pipeline_sample()
    
    # Analisar resultados
    analyze_test_results()
    
    print("\nüéØ PR√ìXIMOS PASSOS:")
    print("1. Se os resultados est√£o bons, execute o pipeline completo")
    print("2. Ajuste os par√¢metros se necess√°rio")
    print("3. Execute: python main_pipeline.py")

if __name__ == "__main__":
    asyncio.run(main())
